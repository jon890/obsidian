## AWS 비용 절감 방법 고민

### Data Transfer

- 주로 서울리전에서 데이터 전송이 발생하고 있으며
- 월간 4,7111GB (4.7TB) 아웃바운드 트래픽이 발생하여 $593.68 청구
	- 이미지는 CloudFront를 활용하여 캐쉬되고 있는 것으로 보여요
	- **`_next/static` 경로 상에 있는 파일들 도 적절히 캐쉬하는 것이 좋아보여요**
		- https://www.arooo.co.kr/_next/static/chunks/webpack-f514f468a253a3b0.js
		- 위와같은 js 파일들도 CloudFront에서 전달하도록 개선할 수 있어 보여요
	- 이 외에도 fonts 파일들도 적절히 캐쉬하는 것이 좋아보여요
		- 위 파일도 CloudFront를 이용하여 전달하도록 개선할 수 있어 보여요
- AZ(동일한 리전 내 동일 가용 영역) 간 데이터 전송 : 5.5TB $55.07 청구
	- AZ간 데이터 발생이 많이 발생하는데 이유를 한 번 찾아봐야할 것 같아요
	- AZ를 사용하시는지? 서울 리전에도 zone 1, 2, 3에 서버를 배치해서 HA 구성이 된 걸까요?
		- asia-norhteast2에도 아마 zone1, 2, 3 이렇게 되어있는 것으로 알고있어요
	- 현재 서버들이 같은 VPC 내에 존재하는지, 다른 가용 영역에 나눠서 배치되어있는지 한 번 확인해보면 좋을 것 같아요.
	- MongoDB가 같은 VPC내에 존재 하지 않아서, 비용이 더 청구될 수 도 있을 것 같아요
	- 하지만 그럼에도 5.5TB를 전송하고 있어서, 이미지나, 용량이 큰 파일을 AZ간 전송하고 있는 것 같아요


### CloudWatch

- 월간 로그 데이터 수집 (PutLogEvents) 에 496GB 로그 저장하여 $377 달러 청구
	- 로그는 어느정도 줄일 필요가 있어보여요, 모든 Req, Res를 쌓는건 불필요해 보여요
	- 혹여나 필요할 경우가 있을 경우를 대비해서, 로그 레벨을 API를 통해 변경할 수 있게 개선하면 좋을 것 같아요
	- 추후에 opensearch + opentelemetry로 전환해도 괜찮을 것 같아요
- 메트릭 모니터링 687개 메트릭으로 $206 달러 청구
	- 서버가 많아서 그런지 메트릭도 꽤나 많이 찍힐 것 같네용
	- 실제로 필요한 메트릭만 기록하도록 조정하는 것도 좋아 보여요
	- 추후에 prometheus + grafana으로 사용하는 것도 좋아 보여요


- 나머지 AWS 비용들은 크게 과금되고 있는 것은 없어보여요
- 정리해보자면..
- next.js에서 전달하는 파일도 캐쉬 되도록 하면 좋을 것 같아요
- 이미지 캐쉬는 이미 사용하고 있지만, 캐쉬 ttl이 어느정도인지 확인해보는 것도 좋을 것 같아요
- AZ간 데이터 전송이 많이 발생하는데 이는 확인이 필요해보여요
	- 멀티 AZ 전략을 사용하고 계신지?
	- 같은 AZ, VPC 내에 서버가 적절히 배치되어있는지
	- MongoDB가 받는 트래픽이 전부라면 몽고로 가지 않게끔 캐쉬레이어를 잘 구성하는 것이 방법이 될 수 있을 것 같아요


## MongoDB 비용 절감 고민

- MongoDB M50 스펙
	- 8Core, 64GB RAM, 1TB
	- **대용량급 스펙으로 이벤트 시, 피크 트래픽이 얼마나 되는지 부하테스트를 해보고, 성능을 적절하게 조정할 필요가 있어보여요**
	- 유휴 시간에 DB가 많이 놀고 있다면, Atlas에서 auto-scaling을 통해 성능을 적절히 낮추는 것도 좋아 보여요
	- DB는 한정된 자원이고, 비싼 자원이니 만큼, 최대한 캐쉬를 통해서 DB의 부하를 줄여 주는게 좋아요
		- static한 데이터들 (자주 사용하지만 거의 변하지 않는 데이터, 설정, 카테고리 등)는 애플리케이션(express.js)의 메모리에 올려두고 사용하는 방법으로 개선하면 어떨까요?
			- 하지만 메모리에 올려두면 리프레쉬 하는 다른 방법이 있어야해요, 중간에 메시지 큐를 두고 관리자에서 변경을 하면, 메시지 큐에서 리프레시 하는 메시지를 전송하여, 분산된 서버들이 메모리를 업데이트 하는 방법이 필요해요
		- 2순위로는 자주 읽지만 업데이트가 빠르지않은 Hot 게시물같은 게시물성은 Redis에서 캐쉬되면 좋을 것 같아요
			- 분산된 서버들이 먼저 Redis에서 데이터를 가져와서 없다면 MongoDB를 호출하고, 캐쉬에 업데이트하는 방식으로 구현하면 될 것 같아요
			- 이를 위해 추상화된 캐쉬 접근 방식이 필요할 것 같아요